{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5UcEyOH1guU927iWlhoZ1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zi-onion/ESAA/blob/main/03_18_Sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CH2.사이킷런으로 시작하는 머신러닝"
      ],
      "metadata": {
        "id": "9jZQNrYgtfYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 사이킷런 소개와 특징\n",
        "사이킷런(scikit- learn): 파이썬 머신러닝 라이브러리 중 가장 많이 사용되는, 파이썬 기반의 머신러닝을 위한 가장 쉽고 효율적인 개발 라이브러리를 제공\n",
        "\n",
        "특징\n",
        "1. 파이썬 기반의 다른 머신러닝 패키지도 사이킷런 스타일의 API를 지향할 정도로 쉽고 가장 파이썬스러운 API를 제공\n",
        "2.  머신러닝을 위한 매우 다양한 알고리즘과 개발을 위한 편리한 프레임워크와 API를 제공\n",
        "3. 오랜 기간 실전 환경에서 검증되었으며, 많은 환경에서 사용되는 성숙한 라이브러리\n"
      ],
      "metadata": {
        "id": "esEzQ2kotl9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "5QYa3RDL-mYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측\n",
        "\n",
        "붓꽃 데이터 세트: 꽃잎의 길이와 너비, 꽃받침의 길이와 너비 피처(Feature)를 기반으로 꽃의 품종을 예측하기 위한 것\n",
        "\n",
        "###[분류(Classification)]\n",
        ": 대표적인 지도학습(SupervisedLearning)방법의 하나\n",
        "\n",
        "* 지도학습: 다양한 피처와 분류 결정값인 레이블(Label)데이터로 모델을 학습한 뒤, 별도의 테스트 데이터 세트에서 미지의 레이블을 예측하는 방식.\n",
        "\n",
        "* **sklearn.datasets**: sklearn.datasets 내의 모듈은 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임\n",
        "* **sklean.tree**: sklean.tree내의 모듈은 트 리 기반 ML알고리즘을 구현한 클래스의 모임\n",
        "* **sklearn.model_selection**: 학습 데이터와 검증 데이터, 예측 데이터로 데이터를 분리하거나 최적의 하이퍼파라미터로 평가하기 위한 다양한 모듈의 모임\n"
      ],
      "metadata": {
        "id": "or0q_Td_udfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iyzrBwyM-p7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트를 로딩합니다.\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다.\n",
        "iris_data = iris.data\n",
        "\n",
        "#iris. target은붓꽃데이터세트에서레이블(결정값)데이터를 numpy로가지고있습니다.\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다.\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "id": "CMAuc_hA-t_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train.test.split(): 학습데이터와 테스트 데이터를 test_size 파라미터 입력 값의 비율로 쉽게 분할."
      ],
      "metadata": {
        "id": "yzL1WhYzwr8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 데이터와 테스트용 데이터를 분리\n",
        "X_train, X_test, y_train, y_test =train_test_split(iris_data, iris_label,\n",
        "test_size=0.2, random_state=11) # random_state는 호출 할 때마다 같은 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 발생 값"
      ],
      "metadata": {
        "id": "vzq-muUf_Bs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 머신러닝 분류 알고리즘의 하나인 의사결정트리를 이용해 학습과 예측을 수행\n",
        "\n",
        "#DecisionTreeClassifier 객체생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xoTxAZ6p_EeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "precict( )메서드: 테스트용 피처 데이터 세트를 입력해 호출하면 학습된 모델 기반에서 테스트 데이터 세트에 대한 예측값을 반환\n"
      ],
      "metadata": {
        "id": "5STc7cxAxZ9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행.\n",
        "pred = dt_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "TGBjp5FJ_LI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy_score(실제, 예측): 정확도 측정\n"
      ],
      "metadata": {
        "id": "-p7hCBk4xqgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측성능 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측정확도:{0:4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "id": "cz9XmBsN_O1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 사이킷런의 기반 프레임워크 익히기\n",
        "\n",
        "### Estimator 이해 및 fit(), predict()메서드\n",
        "Estimator 클래스: 분류 알고리즘을 구현한 클래스 Classifier, 회귀 알고리즘을 구현한 클래스 Regresor 클래스를 합쳐서 지칭. 즉,지도학습의 모든 알고리즘을 구현한 클래스\n",
        "\n",
        "Estimator 클래스의 분류와 회귀의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 는fit()과 predict()만을 이용해 간단하게 학습과 예측 결과를 반환.\n",
        "\n",
        "\n",
        "###사이킷런의 주요 모듈\n",
        "예제 데이터\n",
        "* sklearn.datasets\n",
        "\n",
        "피처 처리\n",
        "* sklearn.preprocessing\n",
        "* sklearn.feature_selection\n",
        "* sklearn.feature_extraction\n",
        "\n",
        "피처처리 & 차원 축소\n",
        "* sklearn.decomposition\n",
        "데이터분리. 검증 &파라미터 튜닝\n",
        "* sklearn.model_selection\n",
        "\n",
        "평가\n",
        "* sklearn.metrics\n",
        "\n",
        "ML알고리즘\n",
        "* sklearn.ensemble\n",
        "* sklearn.linear_model\n",
        "* sklearn.naive_bayes\n",
        "* sklearn.neighbors\n",
        "* sklearn.svm\n",
        "* sklearn.tree\n",
        "* sklearn.cluster\n",
        "\n",
        "유틸리티\n",
        "* sklearn pipeline\n",
        "\n",
        "\n",
        "###내장된 예제 데이터 세트: datasets 모듈의 API\n",
        "* 분류나 회귀를 연습하기 위한 예제용도의 데이터 세트와 분류나 클러스터링을 위해 표본 데이터로 생성 될 수 있는 데이터 세트로 나뉨.\n",
        "* fetch계열의 명령은 데이터의 크기가 커서 패키지에 처음부터 저장돼 있지 않고 인터넷에서 내려받아 홈 디렉터리 아래의 scikit_learn_data라는 서브 디렉터리에 저장한 후 추후 불러들이는 데이터"
      ],
      "metadata": {
        "id": "QaAFiNIPx5DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))\n",
        "# Bunch클래스는 파이썬 딕셔너리 자료형과 유사.\n",
        "# 데이터 세트에 내장돼 있는 대부분의 데이터 세트는 이와 같이 딕셔너리 형태의 값을 반환"
      ],
      "metadata": {
        "id": "lHzJOg9Q_csN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "metadata": {
        "id": "nHLFqCna_kjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n feature names의 type:', type(iris_data.feature_names))\n",
        "print('feature_names의 shape:', len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names의 type:', type(iris_data.target_names))\n",
        "print('target_names의 shape:', len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('\\n data의 type:', type(iris_data.data))\n",
        "print(' data의 shape:', iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n target의 type:', type(iris_data.target))\n",
        "print('target의 shape:', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "id": "xE5WTauw_sVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. Model Selection 모듈 소개"
      ],
      "metadata": {
        "id": "VapW27Kb6bJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf =DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 세트로 예측 수행\n",
        "pred =dt_clf.predict(train_data)\n",
        "print('예측 정확도:',accuracy_score(train_label,pred))"
      ],
      "metadata": {
        "id": "v3RwYPTyAdMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dt_clf =DecisionTreeClassifier()\n",
        "iris_data =load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test =train_test_split(iris_data.data, iris_data.target, \\\n",
        "                                                   test_size=0.3, random_state=121)"
      ],
      "metadata": {
        "id": "hNVVdiVtArMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred =dt_clf.predict(X_test)\n",
        "print('예측 정확도:{0:4F}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "id": "w2g_4xiZAzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 교차 검증\n",
        "#### K 폴드 교차 검증"
      ],
      "metadata": {
        "id": "VJJN72vj7MSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris =load_iris()\n",
        "features = iris.data\n",
        "label = iris. target\n",
        "dt_clf =DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 당을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])\n",
        "\n",
        "n_iter =0\n",
        "\n",
        "# KFold 객체의 split()를 호출하면 폴드별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "  # kfold.split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  # 학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter * 1\n",
        "  # 반복 시마다 정확도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도: {1},학습 데이터 크기: {2},검증 데이터 크기: {3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0}검증세트인덱스:{1}'.format(n_iter,test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n ##평균 검증 정확도: ' , np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "gHcyqNR5BALq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stratified K 폴드"
      ],
      "metadata": {
        "id": "wWch0JC78p6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris =load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris. feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "zWUR5EkECNjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter =0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train= iris_df['label'].iloc[train_index]\n",
        "  label_test= iris_df['label'].iloc[test_index]\n",
        "  print('##교차 검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts(), iris_df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "FACrGlU8-ICO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter * 1\n",
        "  label_train= iris_df['label'].iloc[train_index]\n",
        "  label_test= iris_df['label'].iloc[test_index]\n",
        "  print('## 교차 검증:{0}'.format(n_iter))\n",
        "  print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "metadata": {
        "id": "D4tv2mPTENGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "#StratifiedKFold의 split() 호출 시 반드시 레이블 데이터 세트도 추가 입력 필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  # split()으로 반환된 인덱스를 이용해 학습용, 검증용 테스트 데이터 추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0} 교차 검증 정확도:{1}, 학습데이터크기: {2},검증데이터크기:{3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0} 검증 세트 인덱스:{1})'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 교차 검증별 정확도 및 평균 정확도 계산\n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy,4))\n",
        "print('## 평균 검증 정확도: ' , np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "zFqEmPYtEo8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 교차 검증을 보다 간편하게 - cross_val_score()"
      ],
      "metadata": {
        "id": "nPJ8ZAIS_jP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "# 성능 지표는 정확도(accuracy), 교차 검증 세트는 3개\n",
        "scores = cross_val_score (dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도: ', np.round(scores,4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores),4 ) )"
      ],
      "metadata": {
        "id": "aUwU5FJvFxeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GridSearchcV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에"
      ],
      "metadata": {
        "id": "M4Wk-9IN_s_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_parameters = {'max_depth': [1, 2, 3],\n",
        "                   'min_samples_split': [2, 3]\n",
        "}"
      ],
      "metadata": {
        "id": "ZzQ9FRkdAGmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를 로딩하고 학습 데이터와 테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "### 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth': [1,2, 3], 'min_samples_split': [2, 3]}"
      ],
      "metadata": {
        "id": "rJuzJVbGGJxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# param_grid의 하이퍼 파라미터를 3개의 train, test set fold로 나누어 테스트 수행 설정.\n",
        "### refit=True가 default임.True이면 가장 좋은 파라미터 설정으로 재학습시킴.\n",
        "grid_dtree =GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)"
      ],
      "metadata": {
        "id": "SPU5nfL6GmZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꽃 학습 데이터로 param_grid의 하이퍼 파라미터를 순차적으로 학습/평가.\n",
        "grid_dtree.fit(X_train, y_train)\n",
        "\n",
        "# GridSearchCV 결과를 추출해 DataFrame으로 변환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score','split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "id": "Yq4deGgDG0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridsearchcV 최적 파라미터:' , grid_dtree. best_params_)\n",
        "print('GridsearchcV 최고 정확도: {0:4f}'.format(grid_dtree.best_score_) )"
      ],
      "metadata": {
        "id": "FgHcHh6HG_2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator =grid_dtree.best_estimator_\n",
        "\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 학습이 됐으므로 별도 학습이 필요 없음\n",
        "pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도:{0:4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "id": "fmjbFiojHSTw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}