{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOGUvDuOHoPetNliUUF+Rzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zi-onion/ESAA/blob/main/03_11_Sklearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn._version)"
      ],
      "metadata": {
        "id": "5QYa3RDL-mYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "iyzrBwyM-p7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# 붓꽃 데이터 세트를 로딩합니다.\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 Iris데이터 세트에서 피처(feature)만으로 된 데이터를 numpy로 가지고 있습니다.\n",
        "iris_data = iris.data\n",
        "#iris. target은붓꽃데이터세트에서레이블(결정값)데이터를 numpy로가지고있습니다.\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)\n",
        "\n",
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환합니다.\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df.head(3)"
      ],
      "metadata": {
        "id": "CMAuc_hA-t_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test =train_test_split(iris_data, iris_label,\n",
        "test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "vzq-muUf_Bs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DecisionTreeClassifier 객체생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "\n",
        "# 학습수행\n",
        "dt_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "xoTxAZ6p_EeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학습이 완료된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행.\n",
        "pred = dt_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "TGBjp5FJ_LI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "라미터로실제레이블데이터세트, 두번째파라미터로예측레이블데이터세트를입력하면됩니다.\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('예측정확도:{0:4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "metadata": {
        "id": "cz9XmBsN_O1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "metadata": {
        "id": "lHzJOg9Q_csN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = iris_data.keys()\n",
        "print('붓꽃데이터세트의키들:', keys)"
      ],
      "metadata": {
        "id": "nHLFqCna_kjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n feature names의 type:', type(iris_data.feature_names))\n",
        "print('feature_names의 shape:', len(iris data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "print('\\n target_names의 type:', type(iris_data.target_names))\n",
        "print('target_names shape:', len(iris_data.target_names))\n",
        "print(iris_data.target_names)\n",
        "\n",
        "print('In data의 type:', type(iris_data.data))\n",
        "print(' data\\ shape:', iris_data.data.shape)\n",
        "print(iris_data['data'])\n",
        "\n",
        "print('\\n targe의 type:', type(iris_data.target))\n",
        "print('target의 shape:', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "id": "xE5WTauw_sVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf =DecisionTreeClassifier()\n",
        "train_data = iris.data\n",
        "train_label = iris.target\n",
        "dt_clf.fit(train_data, train_label)\n",
        "\n",
        "# 학습 데이터 세트로 예측 수행\n",
        "pred =dt_clf.predict(train_data)\n",
        "print('예측 정확도:',accuracy_score(train_label,pred)"
      ],
      "metadata": {
        "id": "v3RwYPTyAdMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model _selection import train_test_split\n",
        "\n",
        "dt_clf =DecisionTreeClassifier()\n",
        "iris_data =load_iris()\n",
        "\n",
        "X_train, X_test, y_train, y_test =train_test_split(iris_data.data, iris_data.target, \\\n",
        "                                                   test_size=0.3, random_state=121)"
      ],
      "metadata": {
        "id": "hNVVdiVtArMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.fit(X_train, y_train)\n",
        "pred =dt_clf predict(X_test)\n",
        "print( 예측정확도:'{0:4F}'.format(accuracyscorely_test, pred)))"
      ],
      "metadata": {
        "id": "w2g_4xiZAzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFodl\n",
        "import numpy as np\n",
        "\n",
        "iris =load_iris()\n",
        "features = iris.data\n",
        "label = iris. target\n",
        "dt_clf =DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "#5개의폴드세트로분리하는KFoLd 객체와폴드세트별정확도를당을리스트객체생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃데이터세트크기':,features.shape[0])\n",
        "\n",
        "n_iter =0\n",
        "\n",
        "#KFold 객체의spl it()를호출하면폴드별학습용, 검증용테스트의로우인덱스를array로반환\n",
        "for train_index, test_index in kfold.split(features):\n",
        "  #kfold.split( )으로반환된인덱스를이용해학습용, 검증용테스트데이터추출\n",
        "  X_train, X_test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index]\n",
        "  #학습및예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred = dt_clf.predict(X_test)\n",
        "  n_iter * 1\n",
        "  # 반 복 시 마 다 정 확 도 측정\n",
        "  accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0}교차검증정확도:(1},학습데이터크기: {2},검증데이터크기:{3}'\n",
        "  .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#(0}검증세트인덱스:{1}'.format(niter,test_index))\n",
        "  cv_accuracy.append(accuracy)\n",
        "\n",
        "# 개별 i t er a t i on 별 정확도를 합하여 평균 정확도 계산\n",
        "print('\\n ##평균 검증 정확도: ' , np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "gHcyqNR5BALq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris =load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris. feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "zWUR5EkECNjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter =0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "  n_iter += 1\n",
        "  label_train= iris_df['label'].iloc[train_index]\n",
        "  label_test= iris_df['label'].iloc[test_index]\n",
        "  print('##교차검증:{0}'.format(n_iter))\n",
        "  print('학습레이블데이터분포:\\n', label_train.value_counts())\n",
        "  print('검증 레이블 데이터 분포:\\n', label_test.value_counts())iris_df['label'].value_counts()\n"
      ],
      "metadata": {
        "id": "FACrGlU8-ICO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedkFold\n",
        "\n",
        "skf = StratifiedkFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "  n_iter * 1\n",
        "  label_train= iris_df['label'].iloc[train_index]\n",
        "  label_test= iris_df['label'].iloc[test_index]\n",
        "  print('## 교차검증:{0}'.format(n_iter))\n",
        "  print('학습레이블데이터분포:\\n', label_train.value_counts())\n",
        "  print('검증레이블데이터분포:In', label_test.value_counts())"
      ],
      "metadata": {
        "id": "D4tv2mPTENGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "#StratifiedKFold의split( )호출시반드시레이블데이터세트도추가입력필요\n",
        "for train_index, test_index in skfold.split(features, label):\n",
        "  # split( )으로반환된인덱스를이용해학습용, 검증용테스트데이터추출\n",
        "  X_train, _test = features[train_index], features[test_index]\n",
        "  y_train, y_test = label[train_index], label[test_index] #학습 및 예측\n",
        "  dt_clf.fit(X_train, y_train)\n",
        "  pred =dt_clf.predict(X_test)\n",
        "\n",
        "  # 반복 시마다 정확도 측정\n",
        "  n_iter += 1\n",
        "  accuracy = np. round(accuracy_score(y_test,pred), 4)\n",
        "  train_size = X_train.shape[0]\n",
        "  test_size = X_test.shape[0]\n",
        "  print('\\n#{0}교차검증정확도:{1}, 학습데이터크기: {2},검증데이터크기:{3}'\n",
        "  .format(n_iter, accuracy, train_size, test_size))\n",
        "  print('#{0}검증세트인덱스:{1})'.format(n_iter, test_index))\n",
        "  cv_accuracy.append(accuracy)"
      ],
      "metadata": {
        "id": "zFqEmPYtEo8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교차검증별정확도및평균정확도계산\n",
        "print('\\n##교차검증별정확도:', np.round(cv_accuracy,4))\n",
        "print('## 평균검증 정확도: ' , np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "C9gZW9NhFNCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_data = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "data = iris_data.data\n",
        "label = iris_data.target\n",
        "\n",
        "#성능지표는정확도(accuracy), 교차검증세트는3개\n",
        "scores = cross_val_score (dt_clf, data, label, scoring='accuracy', cv=3)\n",
        "print('교차 검증별 정확도: ', np.round(scores,4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores),4 ) )"
      ],
      "metadata": {
        "id": "aUwU5FJvFxeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 데이터를로딩하고학습데이터와테스트데이터분리\n",
        "iris = load_iris()\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "## 파라미터를딕셔너리형태로설정\n",
        "parameters = {'max_depth': [1,2, 3], 'min_samples_split': [2, 3]}"
      ],
      "metadata": {
        "id": "rJuzJVbGGJxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#param_grid의하이퍼파라미터를3개의train, test set fold로나누어테스트수행설정. #t refit=True가default임.True이면가장좋은파라미터설정으로재학습시킴.\n",
        "grid_dtree =GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)"
      ],
      "metadata": {
        "id": "SPU5nfL6GmZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓 꽃 학 습 데 이 터 로 p a r am _g r i d 의 하 이 퍼 파 라 미 터 를 순 차 적 으 로 학 습/ 평 가 . grid_dtree.fit(X_train, y_train)\n",
        "# Gr i d s e a r c h c V 결 과 를 추 출 해 D a t a F r a m e 으 로 변 환\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score','splito_test score', 'split1_test score', 'splitz test score']]"
      ],
      "metadata": {
        "id": "Yq4deGgDG0g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' GridsearchcV 최적파라미터:' , grid_dtree. best_params_)\n",
        "print('GridsearchcV 최고정확도: {0:4f}'.format(grid_dtree.best_score_) )"
      ],
      "metadata": {
        "id": "FgHcHh6HG_2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gr i d s e a r c h c v 의 r e f i t 으 로 이 미 학 습 된 e s t i ma t o r 반 환\n",
        "estimator =grid_dtree.best_estimator_\n",
        "\n",
        "# Gr i d s e a r c h c V 의 b e s t _ e s t i ma t o r _ 는 이 미 최 적 학 습 이 됐 으 므 로 별 도 학 습 이 필 요 없 음 pred = estimator.predict(X_test)\n",
        "print('테스트 데이터 세트 정확도:{0:4f}'.format(accuracy.score(y_test,pred)))"
      ],
      "metadata": {
        "id": "fmjbFiojHSTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [개념정리]\n",
        "## 데이터전처리(Data Preprocessing)\n",
        "결손값. 즉 NaN,Null 값은 허용되지 않음\n",
        " - 결손값이 적은 경우: null값을 피처의 평균값으로 대체\n",
        " - 결손값이 많은 경우: 피처를 드롭\n",
        " - 결손값이 일정 수준 이상: 해당 피처가 중요도가 높은 피처이고 Null을 단순히 피처의 평균값으로 대체할 경우 예측 왜곡이 심할 수 있다면 업무로직 등을 상세히 검토해 더 정밀한 대체 값을 선정\n",
        "\n",
        " 문자열 값을 입력으로 허용x\n",
        "  - 문자열 값은 인코딩돼서 숫자형으로 변환\n",
        "  - 카테고리형 피러는 코드값으로 표현\n",
        "  - 텍스트형 피처는 피처 벡터화(feature vectorization) 등의 기법으로 벡터화하거나 불필요한 피처라고 판단되면 삭제\n"
      ],
      "metadata": {
        "id": "aCPh17dG9gVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 데이터 인코딩\n",
        "1. 레이블 인코딩(Label encoding) :카테고리 피처를  코드형 숫자값으로 변환하는 것\n",
        " - LabelEincoder를 객체로 생성한 후 fit( )과 transform()을 호출해 수행\n",
        " - LabelEncoder 객체의 classes_ 속성값으로 어떤 숫자 값으로 인코딩됐는지 확인\n",
        " - inverse_transform(): 인코딩된 값을 다시 디코딩\n",
        " - 레이블인코딩이 일괄적인 숫자값으로 변환되면서 몇 ML 알 고리즘에는 예측 성능이 떨어지는 경우가 발생할 수 있음. ex.선형회귀 등에서 에러, 트리계열은 무관.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HNrADz-JuDyS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4id9EgmMH7IT"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "#LabelEncoder를 객체로 생성한 후, fit( )과 transform( )으로 레이블인코딩 수행.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값:',labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('인코딩 클래스:', encoder.classes_)"
      ],
      "metadata": {
        "id": "W-yy8iKmwnDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('디코딩 원본값: ', encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
      ],
      "metadata": {
        "id": "ACt3QsPlxLow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 원-핫인코딩(One Hot encoding): 피처 값의 유형에 따라 새로운 피처를 추가해 고유값에 해당하는 칼럼에만 1을 표시하고 나머지 칼럼에는 0을 표시하는 방식\n",
        "- 사이킷런에서 OneHotEncoder 클래스로 쉽게 변환 가능.\n",
        "- 변환 전에 모든 문자열이 숫자형 값으로 변환돼야 함.\n",
        "- 입력 값으로 2차원 데이터가 필요.\n",
        "- get_dummies( ): 판다스에서 원=핫 인코딩을 더 쉽게 지원하는 API / 숫자형 변환 없이 바로 변환 가능."
      ],
      "metadata": {
        "id": "VEV6CaaRwoxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items=['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "\n",
        "#먼저 숫자 값으로 변환을 위해 LabelEncoder로 변환합니다.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels =encoder.transform(items)\n",
        "# 2차원 데이터로 변환합니다.\n",
        "labels = labels.reshape(-1, 1)\n",
        "\n",
        "# 원- 핫 인코딩을 적용합니다.\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(labels)\n",
        "oh_labels = oh_encoder.transform(labels)\n",
        "print( '원-핫 인코딩 데이터' )\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "id": "lphi6ZVSy-Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'item':['TV','냉장고','전자레인지','컴퓨터','선풍기','선풍기','믹서','믹서']\n",
        "                  })\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "dA3QMw2dzuZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 피처 스케일링과 정규화\n",
        "1. 피처 스케일링(feature scaling): 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업\n",
        "  1. 표준화(Standardization) :데이터의 피처 각각이 평균이 0이고 분산이 1인 가우시안 정규 분포를 가진 값으로 변환\n",
        "  - Xi_new = Xi - mean(x) / stdev(x)\n",
        "\n",
        "  2. 정규화(Normalization): 서로 다른 피처의 크기를 통일하기 위해 크기를 변환해주는 개념\n",
        "  - Xi_new = Xi - min(x) / max(x) - min(x)\n",
        "\n",
        "  사이킷런에서의 Normalizer 모듈은 선형대수에서의 정규화 개념이 적용됐으며, 개별 벡터의 크기를 맞추기 위해 변환하는 것을 의미\n",
        "\n",
        "  - Xi_new = Xi / sqrt(xi**2 + yi**2 +zi**2)\n",
        "\n",
        "2. StandardScaler: 개별 피처를 평균이 0이고, 분산이 1인 값으로 변환해주는 클래스(매우 중요한 단계)\n"
      ],
      "metadata": {
        "id": "tFIRDFoU0L6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트를 로딩하고 DataFrame으로 변환합니다.\n",
        "iris = load_iris()\n",
        "iris_data = iris.data\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "\n",
        "print('feature들의 평균값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature들의 분산값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "id": "AaQYsvmM0LqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "# StandardScaler객체 생성\n",
        "scaler = StandardScaler()\n",
        "#StandardScaler로데이터세트변환. fit()과 transform()호출.\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler. transform(iris_df)\n",
        "\n",
        "#transform()시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를 DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 평균값')\n",
        "print(iris_df_scaled.mean())\n",
        "print('\\nfeature들의 분산값')\n",
        "print(iris_df_scaled.var())"
      ],
      "metadata": {
        "id": "MRh7TCFD2oEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. MinMaxScaler: 데이터 값을 0과 1 사이의 범위 값 으로 변환(음수 값이 있으면 -1에서 1값으로 변환), 데이터의 분포가 가우시안 분포가 아닐 경우 적용.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_CuY0mO60ZGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn .preprocessing import MinMaxScaler\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "# MinMaxScaler로 데이터 세트 변환. fit()과 transform() 호출.\n",
        "scaler.fit(iris_df)\n",
        "irisscaled =scaler.transform(iris_df)\n",
        "\n",
        "# transform()시 스케일 변환된 데이터 세트가 Numpy ndarray로 반환돼 이를DataFrame으로 변환\n",
        "iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "print('feature들의 최솟값')\n",
        "print(iris_df_scaled.min())\n",
        "print('\\nfeature들의 최댓값')\n",
        "print(iris_df_scaled.max)"
      ],
      "metadata": {
        "id": "6fm3pQaK3Rba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점\n",
        "  1. 가능하다면 전체 데이터의 스케일링 변환을 적용한 뒤 학습과 테스트 데이터로 분리\n",
        "  2.1이 여의치 않다면 테스트 데이터 변환 시에는 fit()이나 fit_transform()을 적용하지 않고 학습 데이터로 이미 fit()된 Scaler객체를 이용해 transiorm( )으로 변환"
      ],
      "metadata": {
        "id": "Bh_Ju0CL3rt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "#학습 데이터는 0부터 10까지, 테스트 데이터는 0부터 5까지 값을 가지는 데이터 세트로 생성\n",
        "#Scaler 클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1, 1)로 차원 변경\n",
        "train_array =np.arange(0, 11).reshape(-1, 1)\n",
        "test_array = np.arange (0, 6).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "t9ZhKFRC3rc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMaxScaler 객체에 별도의 feature_range 파라미터 값을 지정하지 않으면 0~1값으로 변환\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#fit()하게 되면 train_array 데이터의 최솟값이 0, 최댓값이 10으로 설정.\n",
        "scaler.fit(train_array)\n",
        "\n",
        "#1/10 scale로 train_array 데이터 변환함. 원본10 -〉 1로 변환됨.\n",
        "train_scaled = scaler. transform(train_array)\n",
        "\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터:', np.round(train_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "_mRSXO5e4nLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MinMaxScaler에 test_array를 fit()하게 되면 원본 데이터의 최솟값이 0, 최댓값이 5로 설정됨\n",
        "scaler.fit(test_array)\n",
        "\n",
        "#1/5scale로 test_array 데이터 변환함. 원본 5->1로 변환.\n",
        "test_scaled = scaler. transform(test_array)\n",
        "\n",
        "#test_array의 scale 변환 출력.\n",
        "print('원본 test_array 데이터:',np.round(test_array.reshape(-1), 2))\n",
        "print('Scale된 test_array 데이터:', np. round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "SG5cym525DbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "학습 데이터와 테스트 데이터의 스케일링이 맞지 않음.\n",
        "이렇게 되면 학습 데이터와 테스트 데이터의 서로 다른 원본 값이 동일한 값으로 변환되는 결과를 초래.\n",
        "따라서 머신러닝 모델은 학습 데이터를 기반으로 학습되기 때문에 반드시 테스트 데이터는 학습 데이터의 스케일링 기준에 따라야 함."
      ],
      "metadata": {
        "id": "bi_6Ece25ggZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_array)\n",
        "train_scaled = scaler. transform(train_array)\n",
        "print('원본 train_array 데이터:', np.round(train_array.reshape(-1), 2))\n",
        "print('Scale된 train_array 데이터: ' , np.round(train_scaled.reshape(-1), 2))\n",
        "\n",
        "# test_array에 Scale 변환을 할 때는 반드시 fit()을 호출하지 않고 transform()만으로 변환해야함.\n",
        "test_scaled = scaler.transform(test_array)\n",
        "print('\\n원본 test_array 데이터: ',np.round(test_array.reshape(-1),2))\n",
        "print('Scale된 test_array 데이터:', np.round(test_scaled.reshape(-1), 2))"
      ],
      "metadata": {
        "id": "JOhhb2jo557q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. 사이킷런으로 수행하는 타이타닉 생존자 예측"
      ],
      "metadata": {
        "id": "3KsPOe8MHf_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "titanic_df =dp read csv('./titanic train.csv')\n",
        "titanic_df.head(3)"
      ],
      "metadata": {
        "id": "atBevycJHftA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n 학습데이터정보###\\n')\n",
        "print(titanic_df.info())"
      ],
      "metadata": {
        "id": "nAQM-U5zIAcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)\n",
        "titanic_df['Cabin'].fillna('N', inplace=True)\n",
        "titanic_df['Embarked'].fillna('N', inplace=True)\n",
        "print('데이터세트 Null값 개수', titanic_df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "fKKxQn7NIGwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(' Sex 값 분포 :\\n', titanic_df['ex'].value_counts())\n",
        "print('\\n Cabni 값 분포 :\\n', titanic_df['Cabin'].value_counts())\n",
        "print('\\n Embarked 값 분포: \\n', titanic_df['Embarked'].value_counts())"
      ],
      "metadata": {
        "id": "AkUGrrWMIV0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Cabin'] = titanicdf['Cabin'].str[:1]\n",
        "print(titanic_df['Cabin'].head(3))"
      ],
      "metadata": {
        "id": "SZV2u-isIrLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df.groupby(['Sex', 'Survived'])['Survived'].count()"
      ],
      "metadata": {
        "id": "yrkJXvhTIw2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y=' Survived', hue='Sex', data=titanic_df)"
      ],
      "metadata": {
        "id": "ZuIH501dIzlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tUANAM4lHfSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 age에따라구분값을반환하는수설정.Dataframe의aply1ambda식에사용.\n",
        "def get_category (age):\n",
        "  cat = ' '\n",
        "  if age <= -1: cat = 'Unknown'\n",
        "  elif age <= 5: cat = 'Baby'\n",
        "  elif age <= 12: cat = 'Child'\n",
        "  elif age <= 18: cat = 'Teenager'\n",
        "  elif age <= 25: cat = 'Student'\n",
        "  elif age <= 35 : cat = 'YoungAdult'\n",
        "  elif age <= 60: cat = 'Adult'\n",
        "  else : cat = 'Elderly'\n",
        "\n",
        "  return cat"
      ],
      "metadata": {
        "id": "LdRiahyqIzQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#막대그래프의크기figure를더 크게설정\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# X축의 값을 순차적으로 표시하기 위한 설정\n",
        "group_names =['Unknown','Baby,' 'Child', 'Teenager', 'Student', 'Young Adult','Adult','Elderly']\n",
        "\n",
        "#lambda식에위에서생성한get_category( )함수를반환값으로지정.\n",
        "#get_category(x)는입력값으로' Age' 칼럼값을받아서해당하는 Cat 반환\n",
        "titanic_df['Age_cat'] = titanic_df['Age'].apply(1ambda x : get_category(x))\n",
        "sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)\n",
        "titanic_df .drop('Age_cat', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "_VitrGOlJXyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "def encode_features(dataDF):\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le = le.fit(dataDF[feature])\n",
        "    dataDF[feature] = le.transform(dataDF[feature])\n",
        "  return dataDF\n",
        "\n",
        "titanic_df =encode_features(titanic_df)\n",
        "titanic_df.head()"
      ],
      "metadata": {
        "id": "7qxnx6ixJ2ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nu l l 처 리 함 수\n",
        "def fillna(df):\n",
        "  df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
        "  df['Cabin'].fillna('N', inplace=True)\n",
        "  df['Embarked'].fillna('N', inplace=True)\n",
        "  df['Fare'].fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 머신러닝 알고리즘에 불필요한 속성 제거\n",
        "def drop_features(df):\n",
        "  df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "  return df\n",
        "\n",
        "# 레이블 인코딩 수행.\n",
        "def format_features(df):\n",
        "  df['Cabin'] =df['Cabin'].str[:1]\n",
        "  features = ['Cabin', 'Sex', 'Embarked']\n",
        "  for feature in features:\n",
        "    le = LabelEncoder()\n",
        "    le = le.fit(df[feature])\n",
        "    df[feature] = le.transform(df[feature])\n",
        "  return df\n",
        "\n",
        "# 앞에 서 설정한 데이터 전처리 함수 호출\n",
        "def transform_features(df):\n",
        "  df = fillna(df)\n",
        "  df = drop_features(df)\n",
        "  df = format_features(df)\n",
        "  return df"
      ],
      "metadata": {
        "id": "Fi0pLIRYKD0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#원본데이터를재로딩하고, 피처데이터세트와레이블데이터세트추출.\n",
        "titanic_df =pd.read_csv('./titanic_train.csv')\n",
        "y_titanic_df = titanic_df['Survived']\n",
        "X_titanic_df= titanic_df.drop('Survived', axis=1)\n",
        "\n",
        "X_titanic_df = transform_features(X_titanic_df)"
      ],
      "metadata": {
        "id": "femIIJFGKptO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_titanic_df, y_titanic_df,test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "R7MYeSlQKzOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 결 정 트 리 , R a n d o m F o r e s t , 로 지 스 틱 회 귀 를 위 한 사 이 킷 런 Cl a s s i f i e r 클 래 스 생 성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)\n",
        "rf_clf =RandomForestClassifier(random_state=11)\n",
        "lr_clf = LogisticRegression()\n",
        "\n",
        "#DecisionTreeClassifier 학습/예측/평가\n",
        "dt_clf.fit(X_train, y_train)\n",
        "dt_pred =dt_clf.predict(X_test)\n",
        "print( 'DecisionTreeClassifier 정확도 : {0:4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "\n",
        "#RandomForestClassifier 학습/예측/평가 rf_clf.fit(X_train, y_train)\n",
        "rf_pred =rf_clf.predict(X_test)\n",
        "print('RandomForestClassifier 정확도 :{0:4f)'.format(accuracy_score(y_test, rf_pred)))\n",
        "\n",
        "#LogisticRegression 학습/예측/평가\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred = lr_clf.predict(X_test)\n",
        "print('LogisticRegression 정확도 : {0:.4f}'.format(accuracy_score(y_test, lr_pred)))\n"
      ],
      "metadata": {
        "id": "qSn6As3eK4HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn. model_selection import KFold\n",
        "def exec_kfold(clf, folds=5):\n",
        "  #폴드세트를5개인KFold객체를생성, 폴드수만큼예측결과저장을위한리스트객체생성.\n",
        "  kfold = KFold(n_splits=folds)\n",
        "  scores = []\n",
        "  # KFold 교차 검증 수행.\n",
        "  for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):\n",
        "    # X_ t i t a n i c _ d f 데 이 터 에 서 교 차 검 증 별 로 학 습 과 검 증 데 이 터 를 가 리 키 는 i n d e x 생 성\n",
        "    X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values|test_index]\n",
        "    y_train, y_test = y_titanic_df .values[train_index], y_titanic_df.values[test_index]\n",
        "    #Classifier 학습, 예측, 정확도 계산\n",
        "    clf.fit(X_train, y_train)\n",
        "    predictions = clf .predict(X_test)\n",
        "    accuracy =accuracy_score(y_test, predictions)\n",
        "    scores.append(accuracy)\n",
        "    print(\"교차검증{0}정확도: {1:.4f}\".format(iter_count,accuracy))\n",
        "  # 5개fol d에서의평균정확도계산.\n",
        "  mean_score = np.mean(scores)\n",
        "  print(\"평균정확도: {0:.4f}\".format(mean_score))\n",
        "# exec_kfol d 호출\n",
        "exec_kfold(dt_clf, folds=5)"
      ],
      "metadata": {
        "id": "kNVrbBARLhOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score (dt_clf, X_titanic_df, y_titanic_df, cv=5)\n",
        "for iter_count, accuracy in enumerate(scores):\n",
        "print('교차검증(0}정확도:{1:4f}'.format(iter_count,accuracy))\n",
        "print(\"평균정확도:{0:4f}\".format(np.mean(scores)))"
      ],
      "metadata": {
        "id": "3qZw2Xm1MRLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'max_depth': [2, 3, 5, 10],\n",
        "              'min_samples_split': [2, 3, 5], 'min samples leaf': [1, 5, 8]}\n",
        "\n",
        "grid_dclf = GridSearchCV(dt_clf, param_grid_parameters, scoring='accuracy', cv=5)\n",
        "grid_dclf.fit(X_train, y_train)\n",
        "\n",
        "print('Gridsearchcv 최적 하이퍼파라미터:', grid_dclf.best_params_)\n",
        "print('GridsearchcV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
        "best_dclf = grid_dclf.best_estimator_\n",
        "\n",
        "# Gri d s e a r c h c v 의 최 적 하 이 퍼 파 라 미 터 로 학 습 된 E s t i ma t o r 로 예 측 및 평 가 수 행 .\n",
        "dpredictions = best_dclf.predict(X_test)\n",
        "accuracy =accuracy_score(y_test, dpredictions)\n",
        "print('테스트 세트에서의 DecisionTreeclassifier 정확도: {0:4f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "qJ9J2a7vMaX8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}